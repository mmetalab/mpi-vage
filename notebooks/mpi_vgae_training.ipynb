{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Run the notebook in conda tf env** <br>\n",
    "**Conda activate tf**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "# from node2vec import Node2Vec\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import glob"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import scipy.sparse as sp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import time\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "tf.set_random_seed(0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from vgae.optimizer import OptimizerAE, OptimizerVAE\n",
    "from vgae.model import GCNModelVAE, GCNModelAE\n",
    "from vgae.preprocessing import preprocess_graph, construct_feed_dict, sparse_to_tuple, mask_test_edges_seed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import scipy.sparse as sp\n",
    "import scipy.stats as scs"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize VGAE Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Calculate ROC AUC\n",
    "def get_roc_score_vgae(edges_pos, edges_neg, pos_weight, norm, emb=None):\n",
    "    if emb is None:\n",
    "        feed_dict.update({placeholders['dropout']: 0})\n",
    "        emb = sess.run(model.z_mean, feed_dict=feed_dict)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Predict on test set of edges\n",
    "    adj_rec = np.dot(emb, emb.T)\n",
    "    preds_pos = []\n",
    "    pos = []\n",
    "    for e in edges_pos:\n",
    "        preds_pos.append(sigmoid(adj_rec[e[0], e[1]])) # predicted score for given edge\n",
    "        pos.append(adj_orig[e[0], e[1]]) # actual value (1)\n",
    "\n",
    "    preds_neg = []\n",
    "    neg = []\n",
    "    for e in edges_neg:\n",
    "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]])) # predicted score for given edge\n",
    "        neg.append(adj_orig[e[0], e[1]]) # actual value (0)\n",
    "\n",
    "    preds_all = np.hstack([preds_pos, preds_neg])\n",
    "    labels_all = np.hstack([np.ones(len(preds_pos)), np.zeros(len(preds_neg))])\n",
    "    roc_score = roc_auc_score(labels_all, preds_all)\n",
    "    fpr, tpr, _ = roc_curve(labels_all, preds_all)\n",
    "    precision, recall, _ = precision_recall_curve(labels_all, preds_all)\n",
    "    pr_score = auc(recall, precision)\n",
    "    ap_score = average_precision_score(labels_all, preds_all)\n",
    "    \n",
    "    # val_loss = norm * tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(labels=tf.constant(labels_all), logits=tf.constant(preds_all), pos_weight=pos_weight))\n",
    "    # val_loss = tf.keras.backend.eval(val_loss)\n",
    "\n",
    "    return roc_score, ap_score, fpr, tpr, pr_score, precision, recall"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "species = ['Homo sapiens','Mus musculus','Rattus norvegicus','Escherichia coli','Bos taurus','Pseudomonas aeruginosa','Arabidopsis thaliana','Saccharomyces cerevisiae','Drosophila melanogaster','Caenorhabditis elegans']\n",
    "seed_number = [12345, 22345, 32345, 42345, 52345]\n",
    "index = 0\n",
    "result = {}\n",
    "for spcs in species[:1]:\n",
    "    spcs_temp = {}\n",
    "    for seed_num in seed_number:\n",
    "        print(spcs,seed_num)\n",
    "        # row = [[]]*len(list(result_charc))\n",
    "        mpi_file_name = './features/mpi_network/'+'mpi_'+str(spcs).replace(' ','_')+'.pkl'\n",
    "        df_file_name = './features/mpi_features/'+'feature_df_'+str(spcs).replace(' ','_')+'.pkl'\n",
    "        g = pickle.load(open(mpi_file_name, \"rb\" ))\n",
    "        node_feats = pickle.load(open(df_file_name, \"rb\" ))\n",
    "        features = np.stack(node_feats['features'].values, axis=0)\n",
    "        adj = nx.adjacency_matrix(g,nodelist=node_feats['node'].tolist())\n",
    "        # features = np.random.rand(adj.shape[0],1024)\n",
    "        adj_train, train_edges, train_edges_false, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges_seed(adj, test_frac=.1, val_frac=.1,seed=seed_num)\n",
    "        \n",
    "        x = sp.lil_matrix(features)\n",
    "        features_tuple = sparse_to_tuple(x)\n",
    "        features_shape = features_tuple[2]\n",
    "        # Get graph attributes (to feed into model)\n",
    "        num_nodes = adj.shape[0] # number of nodes in adjacency matrix\n",
    "        num_features = features_shape[1] # number of features (columsn of features matrix)\n",
    "        features_nonzero = features_tuple[1].shape[0] # number of non-zero entries in features matrix (or length of values list)\n",
    "        # Store original adjacency matrix (without diagonal entries) for later\n",
    "        adj_orig = adj\n",
    "        adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "        adj_orig.eliminate_zeros()\n",
    "        # Normalize adjacency matrix\n",
    "        adj_norm = preprocess_graph(adj_train)\n",
    "        # Add in diagonals\n",
    "        adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
    "        adj_label = sparse_to_tuple(adj_label)\n",
    "        cost_val = []\n",
    "        acc_val = []\n",
    "        val_roc_score = []\n",
    "        train_loss_log = []\n",
    "        val_loss_log = []\n",
    "        # Define hyperparameters\n",
    "        LEARNING_RATE = 0.005\n",
    "        EPOCHS = 500\n",
    "        HIDDEN1_DIM = 32\n",
    "        HIDDEN2_DIM = 16\n",
    "        DROPOUT = 0.1\n",
    "        # Define placeholders\n",
    "        placeholders = {\n",
    "            'features': tf.sparse_placeholder(tf.float32),\n",
    "            'adj': tf.sparse_placeholder(tf.float32),\n",
    "            'adj_orig': tf.sparse_placeholder(tf.float32),\n",
    "            'dropout': tf.placeholder_with_default(0., shape=())\n",
    "        }\n",
    "\n",
    "        # How much to weigh positive examples (true edges) in cost print_function\n",
    "        # Want to weigh less-frequent classes higher, so as to prevent model output bias\n",
    "        # pos_weight = (num. negative samples / (num. positive samples)\n",
    "        pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "\n",
    "        # normalize (scale) average weighted cost\n",
    "        norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "        # Create VAE model\n",
    "        model = GCNModelVAE(placeholders, num_features, num_nodes, features_nonzero, HIDDEN1_DIM, HIDDEN2_DIM)\n",
    "\n",
    "        opt = OptimizerVAE(preds=model.reconstructions,\n",
    "                                labels=tf.reshape(tf.sparse_tensor_to_dense(placeholders['adj_orig'],\n",
    "                                                                            validate_indices=False), [-1]),\n",
    "                                model=model, num_nodes=num_nodes,\n",
    "                                pos_weight=pos_weight,\n",
    "                                norm=norm,\n",
    "                                learning_rate=LEARNING_RATE)\n",
    "\n",
    "        # Initialize session\n",
    "        sess = tf.Session()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        # Train model\n",
    "        for epoch in range(EPOCHS):\n",
    "            t = time.time()\n",
    "            # Construct feed dictionary\n",
    "            feed_dict = construct_feed_dict(adj_norm, adj_label, features_tuple, placeholders)\n",
    "            feed_dict.update({placeholders['dropout']: DROPOUT})\n",
    "            # Run single weight update\n",
    "            outs = sess.run([opt.opt_op, opt.cost, opt.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "            # Compute average loss\n",
    "            avg_cost = outs[1]\n",
    "            avg_accuracy = outs[2]\n",
    "            roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall = get_roc_score_vgae(train_edges, train_edges_false, pos_weight, norm)\n",
    "            # train_loss_log.append(train_loss_epoch)\n",
    "\n",
    "            # # Evaluate predictions\n",
    "            roc_curr, ap_curr, fpr, tpr, pr_score, precision, recall = get_roc_score_vgae(val_edges, val_edges_false, pos_weight, norm)\n",
    "            val_roc_score.append(roc_curr)\n",
    "            # val_loss_log.append(val_loss_epoch)\n",
    "            \n",
    "            if (epoch+1)%50 == 0:\n",
    "            # Print results for this epoch\n",
    "                print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(avg_cost),\n",
    "                    \"train_acc=\", \"{:.5f}\".format(avg_accuracy), \"val_roc=\", \"{:.5f}\".format(val_roc_score[-1]),\n",
    "                    \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
    "                    \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "        print(\"Optimization Finished!\")\n",
    "        # Print final results\n",
    "        feature_roc_score, feature_ap_score, feature_fpr, feature_tpr, feature_pr_score, feature_prcs, feature_rcal = get_roc_score_vgae(test_edges, test_edges_false, pos_weight, norm)\n",
    "        temp = [feature_roc_score, feature_ap_score, feature_fpr, feature_tpr, feature_pr_score, feature_prcs, feature_rcal]\n",
    "        print('Test ROC score: ' + str(feature_roc_score))\n",
    "        print('Test AP score: ' + str(feature_ap_score))\n",
    "        spcs_temp[seed_num] = temp\n",
    "    result[spcs] = spcs_temp\n",
    "pickle.dump(result,open('./graph_model_vgae_features.pkl','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "317.2146911621094px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "interpreter": {
   "hash": "3fe952b0ba1daa6ee3393e62a893871d88149d9d44cf2ee1c1e3a6730bdcafed"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}